{"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2023/11/26/hello-world/"},{"title":"Python基础(一)","text":"多线程，多进程，进程间数据通信 Python多线程 一个进程至少包含一个主线程（守护线程），也可以包含许多子线程（非守护线程）。 Python程序为了线程安全，每一个进程设有一个全局解释器锁，不同的操作系统对线程的占用时间时有限的，当Python程序执行时每一个线程都需要排队去申请解锁，在有限的占用时间后还锁，这就造成Python多线程程序同一时刻只能有一个线程在运行，但由于操作系统切换线程速度太快，就看似是一种并发的状态，但其实是伪并发。 Python要实现真并发，可以使用多进程。 对于爬虫来说主要在等待I/O的请求时间，所以多线程完全可以使用。 threading，多线程包 基础使用 设置线程 开启线程 其他：设置守护线程，查看线程状态 12345678910111213141516171819202122232425262728293031323334import threadingdef print1(): for i in range(100): print(&quot;1&quot;)def print2(): for i in range(100): print(&quot;2&quot;)#target=函数名，args=传入参数x1=threading.Thread(target=print1,args=())x2=threading.Thread(target=print2,args=())#设置为守护线程# x1.daemon=True# x2.daemon=True#开启线程#主线程接受不影响非守护线程x1.start()x2.start()#判断是否为守护线程# print('x1',x1.daemon)# print('x2',x2.daemon)print(&quot;主线程结束&quot;)#查看线程状态#print(threading.current_thread())#查理主线程状态#print(threading.main_thread()) 上锁 使用 threading.Lock() 进行上锁等待，上文说到在有限的的时间内会将锁还回去（但保留运行数据，再次轮到后继续进行），任务开始使用 .acquire获取锁，可以强制等待任务执行完毕后使用 .release 再还锁。 .join()的作用，主线程任务结束后进入阻塞状态，会一直等待调用了join子线程任务执行结束后主线程才会终止。 用时间换安全 使用一个循环加一减一的例子说明 1234567891011121314151617181920212223242526272829303132import threadingLock=threading.Lock()num = 0def print1(): global num for i in range(100): Lock.acquire() num+=1 Lock.release()def print2(): global num for i in range(100): Lock.acquire() num-=1 Lock.release()#target=函数名，args=传入参数x1=threading.Thread(target=print1)x2=threading.Thread(target=print2)x1.start()x2.start()x1.join()x2.join()print(num) Python多进程 multiprocessing包 基本使用 设置线程–启动线程–给每个线程添加等待 12345678910111213141516171819202122import multiprocessingimport time# 查看电脑线程数# print(multiprocessing.cpu_count())def num(name): print('run process{}'.format(name)) time.sleep(3) print('end process{}'.format(name))if __name__ == '__main__': # 设置线程--启动线程--给每个线程添加等待 processes=[] for i in range(5): p1=multiprocessing.Process(target=num,args=(i,)) processes.append(p1) p1.start() for i in processes: i.join() print('进程结束') 进程池构建 在一开始创建一个进程池，那个空闲用那个，用完自动还回去 123456789101112if __name__ == '__main__'： Pools=multiprocessing.Pool(3) for i in range(9): #Pools.apply(func=num,args=(i,))#apply同步 Pools.apply_async(func=num,args=(i,))#apply_async异步(主要使用异步) Pools.close()#使用结束后关闭全部进程池 Pools.join() print('进程结束') 多进程数据共享 原理：使用代理 Manager 使用代理复制一份数据进行同步更改 不是共享内存 123456789101112131415161718192021222324252627282930import multiprocessingimport timedef push(li): print(id(li)) while True: print(&quot;存数据&quot;) li.append('a') time.sleep(1)def pop(li): print(id(li)) while True: if li: print('拿数据'+str(li.pop())) time.sleep(1)def main(): #设置代理Manager（列表） li = multiprocessing.Manager().list() print(id(li)) p1 = multiprocessing.Process(target=push,args=(li,)) p2 = multiprocessing.Process(target=pop, args=(li,)) p1.start() p2.start() p1.join() p2.join()if __name__ == '__main__': main()","link":"/2023/08/06/python1/"},{"title":"Python基础(二)","text":"异步协程 异步:在单线程中利用IO等待时间去执行其他任务 携程:一个个没有并发起来的任务，协程本身不会多个并发需要我们包装成任务 注意: 如果不加await 则任务只是一个声明不会运行，await + 等待执行的任务 在等待程序前面加上asyncio表示这是个异步程序 123456789101112131415161718192021222324import asyncioasync def num(name): print('{}start'.format(name)) await asyncio.sleep(2) print('{}end'.format(name))async def main(): t1=[asyncio.create_task(num(1)), asyncio.create_task(num(2)), asyncio.create_task(num(3))] await asyncio.wait(t1)#两种写法效果一样# async def main():# t1 = [num(1),# num(2),# num(3)]# await asyncio.gather(*t1)if __name__ == '__main__': #声明协程对象 并不会直接运行 #await运行协程任务 等待 会一直阻塞到任务结果返回 asyncio.run(main())","link":"/2023/08/06/python2/"},{"title":"Python基础(四)","text":"类，装饰器，文件操作 类123456789101112131415161718192021222324252627282930#参数叫属性#函数叫方法class Human: # 初始化 def __init__(self,name): # 指针指向self内存地址 # self 放在内存里的一个Human对象 self.name=name print('self-&gt;',self) # 像调用函数一样调用类 def __call__(self, *args, **kwargs): print('call 被调用',args,kwargs) #call 被调用 (1, 2, 3, 'nihao') {'name': 'nihao', 'age': 9} #*args和*kwargs会把值解出来 #call 被调用 1 2 3 nihao name age print('call 被调用',*args,*kwargs) def speak(self): print('Human在讲话'+self.name)#实例化会自动调用init方法h1=Human(&quot;h1&quot;)print(h1.name)h1.speak()h2=Human(&quot;h2&quot;)print(h2.name)h2.speak()#像调用函数一样调用类#前面的数据会被*args接收，后面的两个赋值运算会被当作键值对被**kwargs接收h1(1,2,3,'nihao',name='nihao',age=9) 继承 封装 多态1234567891011121314151617181920212223242526272829303132class Human: def __init__(self,name,age): self.name=name #下划线开头代表私有 self.__age = age print('self-&gt;',self) def speak(self): print('Human在讲话'+self.name) #下划线开头代表私有 def __speak(self): print('Human在讲话'+self.name)#继承class nihao(Human): def __init__(self,name,age): self.nihao=name self.age = age #调用父类__init__方法 super(nihao, self).__init__(name,age) # 多态 重写父类 def speak(self): print('nihao') #在同名子类中调用父类 super(nihao, self).speak()def speak(obj): obj.speak()x1=nihao(&quot;nihao&quot;,2)x2=Human(&quot;nihao2&quot;,1)speak(x1)speak(x2) 12345678910111213141516171819202122#property 把类方法转化为类属性方式获取#classmethod 类方法表示属于类，不属于实例#staticmethod 静态方法 我当前的方法不属于类 是一个单独的函数class nihao: def __init__(self): self.age ='4' @property def _age(self): return self.age #设置属性 @_age.setter def _age(self,value): self.age=value #删除属性 @_age.deleter def _age(self): del self.agen = nihao()del n._agen._age = 5print(n._age) 装饰器12345678910111213141516171819202122#自制装饰器#高阶函数---把函数作为参数#参数是函数 返回内部函数 内部函数里边调用函数（传递参数）import timedef Timer(func): #start=time.time() def inner(*args,**kwargs): #print('传递的参数：',*args,**kwargs) func(*args,**kwargs) # end=time.time() # print('耗费时间：',end-start) return inner@Timerdef test(a,b,c): for i in range(100000): print(1)test(1,2,3) 文件操作12345678910111213141516171819202122&quot;&quot;&quot;w 写入 如果文件不存在我就创建 已经存在就会覆盖r 读取 读取文件内容a 追加 把内容写入文件末尾，不存在就创建，存在就直接写b 二进制 写入视频、音频、图片之类的就需要加这个with自开合 enter exit&quot;&quot;&quot;line=&quot;写入文件&quot;#第一种写法f=open('demo.txt','w',encoding='utf-8')f.write(line)f.close()#不关闭那就会导致内存泄漏（文本打开太多了，内存爆了）#第二种写法for i in range(10): with open('demo.txt','a',encoding='utf-8')as f: f.write(line+'\\n')# 读with open('demo.txt','r',encoding='utf-8')as fr: content=fr.read()print(content)","link":"/2023/08/08/python4/"},{"title":"Python基础(五)","text":"python三器 迭代器和生成器迭代器：标志是使用__iter__方法，返回一个迭代器对象使用__next__方法可以获取下一个值，如果没有下一个值则抛出StopIteration异常 迭代器是一个可以记住遍历的位置的对象，可以为序列、文件、集合、字典、字符串等对象 迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束 迭代器只能往前不会后退 迭代器是有状态的，每次迭代都需要重新设置状态 生成器：生成器是一个特殊的迭代器，只能往后不会前进，标志是使用yield关键字，返回一个生成器对象 生成器是一个特殊的函数，只能用于迭代操作，返回迭代器对象 生成器是一个惰性计算的对象，只有在需要迭代的时候才会执行，节省内存 生成器可以不断返回下一个值，直到没有更多的值 装饰器装饰器是一个特殊的函数，它可以让其他函数增加额外的功能，其定义格式如下： 12345def decorator_name(func): def wrapper(*args, **kwargs): # 包装操作 return func(*args, **kwargs) return wrapper 装饰器的作用就是将原函数的内容包装起来，然后返回包装后的函数。 Python中如何实现单例模式 单例模式是一种常见的设计模式，它保证一个类只有一个实例，并提供一个访问它的全局访问点。123456789101112131415161718192021222324252627282930313233343536373839404142# 实现方式一：# 使用装饰器实现 判断是否已经实例化from functools import wrapsfrom typing import Anydef singleton(cls): &quot;&quot;&quot; 单列类装饰器 &quot;&quot;&quot; instance = {} @wraps(cls) def wrapper(*args, **kwargs): if cls not in instance: instance[cls] = cls(*args, **kwargs) return instance[cls] return wrapper@singletonclass Singleton: &quot;&quot;&quot; 单列类 &quot;&quot;&quot; passa = Singleton()b = Singleton()print(id(a), id(b))# 实现方式二：# 使用元类实现单例类(类这样的对象时通过元类来创建，默认元类为type)class Singleton2(type): &quot;&quot;&quot; 单列类元类 &quot;&quot;&quot; def __init__(cls,*arg,**kwargs): print('init') cls.__instance = None super().__init__(*arg,**kwargs) def __call__(cls,*arg,**kwargs): print('call') if cls.__instance is None: cls.__instance = super().__call__(*arg,**kwargs) return cls.__instanceclass President(metaclass=Singleton2): pass a = President()b = President()print(id(a), id(b))","link":"/2023/08/13/python5/"},{"title":"请求库","text":"介绍爬虫使用的请求库，requests，httpx，aiohttp。 requests 请求数据 get post 添加参数 user-agent 请求浏览器数据 date 数据 param 参数 cookie 防盗链 referer 请求超时 timeout=3 结果处理 二进制 文本text json数据 代码123456789101112131415161718192021222324252627282930313233343536import requestsurl = '这写上要爬的url'#添加头 headers = { &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)&quot;\\ &quot;Chrome/107.0.0.0 Safari/537.36 Edg/107.0.1418.52&quot;,}#添加数据date = { &quot;kw&quot;: s}#添加参数（重新封装）params = { &quot;type&quot;: 20, &quot;interval_id&quot;: &quot;100:90&quot;, &quot;action&quot;: &quot;&quot;, &quot;start&quot;: 0, &quot;limit&quot;: 20,}#发起一个get请求resp = requests.get(url, headers=headers，data=data，params=params)#发起一个post请求resp = requests.post(url, headers=headers，data=data，params=params)#去掉安全验证resp = requests.get(url, verify=False)#设置编码格式resp.encoding = 'utf8'#状态码查看print(resp.status_code)#结果为二进制print(resp.content)#结果为json数据print(resp.json())#请求为文本print(resp.text) 中文解码12345678910import requestsfrom urllib.parse import quote,unquote#解码data='%E4%BD%A0%E5%A5%BD'print(unquote(data))#加码data2='你好'print(quote(data)) session会话 session对象 基于seesion发起的请求都会公用session内的参数。 session可以保存请求时的cookie12345678910import requestssession = requests.session()session.headers={ 'test':'test'}#请求是公用session中的参数，也可以自己添加，如果参数重合以自己的请求为主h1 =session.get('url',headers={'a':'b'})h2 =session.get('url') proxies代理123456import requestsproxies ={ 'http':'http://127.0.0.1:7890', 'https':'http://127.0.0.1:7890',}resp = requests.get('url',proxies=proxies) httpx 支持http2.0兼容http1.0 处理http1.0和requests一样的用法 12345import httpxheaders={}proies={}html = httpx.get('url',headers=headers,proies=proies)print(html.text) 处理http2.0和session用法相似 client=httpx.Client(http2.0=True,proxies=proxies) 异步请求 12345678910111213141516171819202122#第一中写法async def spider(num): print('run',num) client=httpx.AsyncClient(http2=True) html = await client.get('url') print(html) await client.aclose()#第二中写法async def spider(num): print('run',num) async with httpx.AsyncClient(http2=True) as client: html = await client.get('url') print(html)#建立队列async def main(): await asyncio.gather(*[spider(1),spider(2),spider(3)])#启动 if __name__ == '__main__': asyncio.run(main()) aiohttp 异步请求 123456789101112131415import aiohttpimport asyncioheaders={}#只支持http代理proxy='http://localhost:7890'async def main(): async with aiohttp.ClientSession(headers=headers) as client: html = await client.get('url') print(await html.text()) html.close()#使用loop启动程序loop = asyncio.get_event_loop()loop.run_until_complete(main()) 优缺点和区别 requests 同步 httpx 同步异步 aiohttp 只有异步","link":"/2023/08/01/spider1/"},{"title":"免费代理处理","text":"免费代理测试验证ip可用性 1.通过爬虫爬取免费代理ip和端口号2.对每个ip进行可用性验证，请求’https://httpbin.org/ip'判断状态码 12345678910111213141516171819#封装proxyproxies = { 'http': f'http://{IP}:{PORT}', 'https': f'http://{IP}:{PORT}',}url = 'https://httpbin.org/ip' headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'\\ 'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36 Edg/109.0.1518.78' } try: html = requests.get(url, proxies=proxies, headers=headers, timeout=3) print('状态码：', html.status_code) print('IP：', html.text) #可用的代理放入列表种 proxies_list.append(proxies) except: print('代理不可用')","link":"/2023/08/01/spider2/"},{"title":"解析库","text":"使用bs4，xpath，re进行数据解析和提取。 bs4 BeautifulSoup 支持从HTML或XML文件中提取数据的python库 Beautiful Soup自动将输入文档转换为Unicode编码，输出文档转换为utf-8编码。 select方法需要使用css选择器 css选择器 class 使用·代替 id使用#代替 find方法是找到第一个满足条件的标签后就立即返回，只返回一个元素。 find_all方法是把所有满足条件的标签都选到，然后返回回去。 12345678910111213141516171819202122232425262728293031323334import requestsfrom bs4 import BeautifulSoup# 从bs对象中查找数据# find(标签，属性=值)# find_all(标签，属性-值（如果遇到python关键字用class_或者一个字典代替）)url = &quot;https://www.umei.cc/bizhitupian/diannaobizhi/&quot;resp = requests.get(url)resp.encoding = 'utf-8'#把爬下来的网站给bs并指定html解析# find(标签，属性=值)# find_all(标签，属性-值（如果遇到python关键字用class_或者一个字典代替）)main_page = BeautifulSoup(resp.text, &quot;html.parser&quot;)#main_page = BeautifulSoup(resp.text, &quot;lxml&quot;)a_list = main_page.find(&quot;div&quot;, class_=&quot;listlbc_cont_l&quot;).find_all(&quot;a&quot;)a_list = main_page.find(&quot;div&quot;, class_=&quot;item_list infinite_scroll&quot;).find_all(&quot;a&quot;)for a in a_list: href = a.get('href') print(href)#使用css选择器 调用select方法b_list = main_page.select('div.img div.btns a')#第一种写法for b in b_list: href = b.get('href') print(href)#第二种写法for b in b_list: print(b['href']) xpath //div找全部的div /div找第一个div @＋属性 严格匹配 鼠标右键复制完整xpath再元素控制台调试直到合适 12345678910111213141516import requestsfrom lxml import etreeurl = &quot;https://www.umei.cc/bizhitupian/diannaobizhi/&quot;resp = requests.get(url)resp.encoding = 'utf-8'soup = etree.HTML(resp.text)#text() @href @属性results=soup.xpath('/html/body/div[5]/div[1]/div[2]/div[1]/div/div/div[1]/div/a/img/@alt')results=soup.xpath('/html/body/div[5]/div[1]/div[2]/div[1]/div/div/div[1]/div/a/img/text()')for i in results: print(i) re re在爬虫种主要处理复杂的数据 使用正则设置一个匹配规则 得到一个list，使用group方法取出 1234567import re# （？P&lt;分组名字&gt;正则）可以单独从正则匹配的内容中进一步提取内容#re.S使.也可以匹配换行符obj = re.compile(r&quot;&lt;div class='.*?'&gt;&lt;span id='.*?'&gt;(?P&lt;分组&gt;.*?)&lt;/span&gt;&lt;div&gt;&quot;, re.S)result = obj.finditer(resp.text)for it in result: print(it.group(&quot;分组&quot;)) 总结爬虫解析页面主要使用bs4和xpath，如果遇到较为复杂的页面使用re即可。","link":"/2023/08/01/spider3/"},{"title":"Python基础(三)","text":"python基础语法 python编译原理 .py文件—编译器—pyCodeObject(内存)/.pyc(磁盘)—虚拟机VM—解释执行—机器码PC 数据类型 str int float bool list dict tuple set str “”12345#字符串 和引号无关str_a='nihao'str_b=&quot;nihao&quot;str_c=&quot;&quot;&quot;nihao&quot;&quot;&quot;print(str_a,str_b,str_c) int float1234int_a=123456float_a=3.1415926print(int_a,float_a)print(type(int_a)) bool123bool_a=Trueprint(type(bool_a),bool_a)print(0==False) list []1234567list_a=[1,2,3,3.14,'nihao','buhao',[5,6,7]]print(list_a)list_a[4]='你好'print(list_a)#删除del list_a[0]print(list_a) dict {key:value}123456dict_a={'name':'xxx','age':100,'port':8000}print(dict_a['name'])dict_a['name']='nihao'print(dict_a)del dict_a['age']print(dict_a) tuple ()1234#类似列表 不能更改 ()tuple_a=('human',99,55,22)print(tuple_a,type(tuple_a))print(tuple_a[0]) set {}123456#集合，过滤重复元素 {}list_b=[1,2,3,5,4,2]set_a=set()for i in list_b: set_a.add(i)print(set_a) 基本语法 break 跳出当前循环 ,continue 继续下一次循环 if else123456username=input(&quot;请输入用户名：&quot;)if username=='nihao': print('登陆成功') breakelse: print('用户名错误,请重新输入') 循环123456789#while死循环-结束条件while True: username=input(&quot;请输入用户名：&quot;) if username=='xjb': print('登陆成功') break else: print('用户名错误,请重新输入')print('程序结束') 123456789#for计次for i in range(10): username=input(&quot;请输入用户名：&quot;) if username=='xjb': print('登陆成功') break else: print('用户名错误,请重新输入')print('程序结束') 循环计数123456789# 循环时候计数enumerateli=['nihao','nihao2','nihao3']for num,item in enumerate(li): print(num+1,item)# 1 nihao# 2 nihao2# 3 nihao3 1234567891011#多个序列打包循环 zipli=[1,2,3,4]li2=[4,5,6,7]li3=[4,5,6,7]for i,j,z in zip(li,li2,li3): print(i,j,z)# 1 4 4# 2 5 5# 3 6 6# 4 7 7 定义函数1234567def add(a,b): print(a+b) # 不写return默认返回None return a+b tmp=add(5,3)print(tmp) 错误处理123456789101112def add(a,b): try: c=a+b print('a+b=',c) # except：可以指定错误类型 except Exception as e: print('发生错误了！',e) finally: #不管正确与否都执行finally print('执行finally')add(1,3)","link":"/2023/08/07/python3/"}],"tags":[{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"爬虫","slug":"爬虫","link":"/tags/%E7%88%AC%E8%99%AB/"}],"categories":[{"name":"5.编程基础","slug":"5-编程基础","link":"/categories/5-%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/"},{"name":"1.Python","slug":"5-编程基础/1-Python","link":"/categories/5-%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/1-Python/"},{"name":"1.爬虫","slug":"1-爬虫","link":"/categories/1-%E7%88%AC%E8%99%AB/"},{"name":"1.爬虫基础","slug":"1-爬虫/1-爬虫基础","link":"/categories/1-%E7%88%AC%E8%99%AB/1-%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80/"}],"pages":[{"title":"","text":"Title *{ margin: 0; padding: 0; font-family: \"Poppins\", sans-serif; box-sizing: border-box; } .mycontainer .mycard .face{ position: absolute; top: 0; left: 0; width: 100%; height: 100%; transition: 0.5s; } .mycontainer .mycard .face.face1{ background: transparent; display: flex; justify-content: center; align-items: center; z-index: 1; transform-origin: bottom; } .mycontainer .mycard .face.face1 img{ max-width: 150px; } .mycontainer .mycard .face.face1 h3{ margin: 10px 0 0; color: #fff; text-align: center; font-size: 1.5em; } .mycontainer .mycard .face.face2 a{ color: rgb(0, 191, 255); text-align: center; font-size: 1.5em; } 1-爬虫基础 2-Scrapy 3-验证码处理 4-抓包工具 1-Js密码学 2-Python密码学 3-Js混淆 4-Js补环境 1-轻量级数据库 1-轻量级数据库 2-MySql 3-Mongodb 4-Redis","link":"/classification/index.html"},{"title":"","text":"Title :root { --fontColor: white; --one1: #c39edc; --one2: white; --two1: #3dbbc7; --two2: white; --three1: #21bbfe; --three2: white; --four1: #122c9e; --four2: white; --levelShadow: #22325480; } .levels { position: relative; top: 50%; left: 50%; margin-left: -140px; margin-top: 100px; transform-style: preserve-3d; user-select: none; } .levels .level { width: 400px; height: 210px; border-radius: 12px; color: var(--fontColor); cursor: pointer; transition: all 0.4s ease; transform: rotateX(37deg) rotateY(-20deg) rotate(15deg); opacity: 0.9; margin-top: -70px; } .levels .level.one { background: linear-gradient(135deg, var(--one1), var(--one2)); box-shadow: 20px 20px 60px var(--levelShadow), 1px 1px 0px 1px var(--one2); z-index: 4; } .levels .level.two { background: linear-gradient(135deg, var(--two1), var(--two2)); box-shadow: 20px 20px 60px var(--levelShadow), 1px 1px 0px 1px var(--two2); z-index: 3; } .levels .level.three { background-image: linear-gradient(135deg, var(--three1), var(--three2)); box-shadow: 20px 20px 60px var(--levelShadow), 1px 1px 0px 1px var(--three2); z-index: 2; } .levels .level.four { background-image: linear-gradient(135deg, var(--four1), var(--four2)); box-shadow: 20px 20px 60px var(--levelShadow), 1px 1px 0px 1px var(--four2); z-index: 1; } .levels .level .title { color: white; position: absolute; top: 80px; right: 80px; font-size: 40px; font-weight: bold; } .levels .level .content { position: absolute; font-weight: 700; bottom: 15px; left: 15px; font-size: 16px; } .levels .level:hover { transform: rotateX(37deg) rotateY(-20deg) rotate(18deg) translate(-25px, 50px); opacity: 0.6; } .levels .level:hover:after { transform: translateX(100%); transition: all 2s ease-in-out; } .levels .level::after { content: ''; position: absolute; top: 0px; left: 0; width: 100%; height: 100%; transform: translateX(-100%); background: linear-gradient(60deg, rgba(255,255,255,0) 20%, rgba(255,255,255,0.1), rgba(255,255,255,0) 80%); } Python 爬虫开发 Java Android逆向 后端开发 JavaScript Js逆向 Html+Css 前端开发","link":"/codebase/index.html"},{"title":"","text":"/* *{ margin: 0; padding: 0; font-family: \"Poppins\", sans-serif; box-sizing: border-box; } */ mybody{ height: 500px; display: flex; justify-content: center; background-color: transparents } .mycontainer{ width: 700px; height: 520px; position: relative; /* display: flex; */ justify-content: space-between; /* 开启网格布局 */ display: grid; grid-template-rows: 300px 300px ; grid-template-columns: 300px 300px ; } .mycontainer .mycard{ position: relative; width: 300px; height: 200px; } /* .mycontainer .mycard .face{ position: absolute; top: 0; left: 0; width: 100%; height: 100%; transition: 0.5s; } */ /* .mycontainer .mycard .face.face1{ background: #333; display: flex; justify-content: center; align-items: center; z-index: 1; transform-origin: bottom; } */ /* .mycontainer .mycard .face.face1 h3{ margin: 10px 0 0; color: #fff; text-align: center; font-size: 1.5em; } */ .mycontainer .mycard:hover .face.face1{ transform: translateY(-100%) rotateX(90deg); background: transparent; } .mycontainer .mycard .face.face2{ background: transparent; display: flex; justify-content: center; align-items: center; padding: 20px; transform-origin: top; transform: translateY(100%) rotateX(90deg); } .mycontainer .mycard:hover .face.face2{ transform: translateY(0%) rotateX(0deg); }","link":"/classification/style.css"},{"title":"","text":"碎碎念 h2{ text-align: center; } p{ text-align: center; } 碎碎念 一路有陌路人陪你这一生","link":"/about/index.html"}]}